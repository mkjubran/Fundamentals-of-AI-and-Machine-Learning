{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyOg2lC4Pg48wAoesn+adAGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/LOGISTIC_REGRESSION_AND_ITS_APPLICATION_TO_MULTI_CLASS_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOGISTIC REGRESSION AND ITS APPLICATION TO MULTI-CLASS CLASSIFICATION\n"
      ],
      "metadata": {
        "id": "mkRHIvM06yZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate how to build and evaluate logistic regression models. We will work on a modified version of the cardiovascular dataset from Kaggle (https://www.kaggle.com/code/sulianova/eda-cardiovascular-data/data)."
      ],
      "metadata": {
        "id": "1zUsWaQ03Jhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "jKIAXwrfe6wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to import some libraries that will be used during the creation and evaluation of logistic regression models."
      ],
      "metadata": {
        "id": "I1fH9Wrse_dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF3_Cpo16WX8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "27fY7xYlfKHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the dataset Repository**\n",
        "\n",
        "The prepared dataset after cleaning, removing outliers, and feature engineering can be cloned from the GitHub repository https://github.com/mkjubran/AIData.git as below"
      ],
      "metadata": {
        "id": "Oe_H_szEfL9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./AIData\n",
        "!git clone https://github.com/mkjubran/AIData.git"
      ],
      "metadata": {
        "id": "1aBK80UEfQr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the dataset**\n",
        "\n",
        "The data is stored in the cardio_EDA.csv file. Read the input data into a dataframe using the Pandas library (https://pandas.pydata.org/) to read the data."
      ],
      "metadata": {
        "id": "PsR4rC0bfVuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/AIData/cardio_EDA.csv\",sep=\";\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "b4EU2gr-fd4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Data Info**\n",
        "\n",
        "Display some information about the dataset using the info() method"
      ],
      "metadata": {
        "id": "yH3Bs7tegOXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "q4ncJdvtgQi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 53659 records with 14 features for each record. Twelve features are numeric and the rest are objects (strings)."
      ],
      "metadata": {
        "id": "kMLQzWu9gTPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data and Remove Outliers"
      ],
      "metadata": {
        "id": "eB7BmZ6NgoCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data has been processed in previous notebooks\n",
        "- Data Cleaning: https://github.com/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/EXPLORATORY_DATA_ANALYSIS_%E2%80%93_DATA_CLEANING.ipynb\n",
        "- Feature Selection and Feature Engineering: https://github.com/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/EXPLORATORY_DATA_ANALYSIS_%E2%80%93_FEATURE_SELECTION_AND_FEATURE_ENGINEERING.ipynb\n",
        "\n",
        "As we noticed from the presented sample of the dataset above some features are highly correlated such as the age and the age_year features. So we need to drop one of these features. Besides, we will drop any not needed features such as the 'id' feature."
      ],
      "metadata": {
        "id": "I6VtkSh0gpgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['id','age'],axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "VhDBt-Zlh80m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Categorical Data"
      ],
      "metadata": {
        "id": "xjZQyakaiUEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use hot encoding through the get_dummies() method in pandas to encode the data in the 'gender' and 'smoke' features."
      ],
      "metadata": {
        "id": "WsvvhZVUiVtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1kLKojV1iyhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to drop one of the columns that resulted from the hot encoding of each feature. Also, make sure that the original features ('age' and 'smoke') are dropped too."
      ],
      "metadata": {
        "id": "dAiSWbjYi_73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['gender_female','smoke_No'],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "glXLVzQYjUI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform And Evaluate Logistic Regression"
      ],
      "metadata": {
        "id": "WOdszHgjjcmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing Logistic Regression**\n",
        "\n",
        "We will start by specifying the independent variables and the dependent variable. The independent variables are the features that will be used to predict the target feature (class,label). And the dependent variable is the target feature (class, label)."
      ],
      "metadata": {
        "id": "uAVn-ZTbjgSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# independent variables\n",
        "X=df.drop(['cardio'],axis=1)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "raz1iL76kKAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dependet variable (target feature, class, label)\n",
        "Y=df.cardio\n",
        "Y.head()"
      ],
      "metadata": {
        "id": "eluEJ2uhkihU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we will splitting the dataset into training and testing splits of the dataset, the split ratio is usually 80% training and 20% testing."
      ],
      "metadata": {
        "id": "7V_n4bF0juln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=200)\n",
        "print('Size of the dataset = {}'.format(len(X)))\n",
        "print('Size of the training dataset = {} ({}%)'.format(len(x_train), 100*len(x_train)/len(X)))\n",
        "print('Size of the testing dataset = {} ({}%)'.format(len(x_test), 100*len(x_test)/len(X)))"
      ],
      "metadata": {
        "id": "V0jKXcncjmcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we used a random_state so that the results are reproducible. You should avoid setting this argument in your production code so that the split is random at every run.\n",
        "\n",
        "Now, we will import the logistic regression model from sklearn and train the model using the training split of the dataset."
      ],
      "metadata": {
        "id": "8F-qHhqtk7J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "logreg = linear_model.LogisticRegression()\n",
        "logreg.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "vFjDLuS7lApf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Logistic Regression**\n",
        "\n",
        "To evaluate the model, we will compute the training and testing accuracy using the training and testing splits of the dataset"
      ],
      "metadata": {
        "id": "PBpGz_ZRlSus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Acc_train = logreg.score(x_train, y_train)\n",
        "Acc_test = logreg.score(x_test, y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logitic Regression (%)'])\n",
        "t.add_row(['Training', Acc_train*100])\n",
        "t.add_row(['Testing', Acc_test*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "xuDSO5fglkNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manual Hyperparameter Tuning**\n",
        "\n",
        "Let us try to fine-tune the model parameters to improve the performance of the logistic regressor. We will increase the maximum number of iterations (max_iter). The default value is 100."
      ],
      "metadata": {
        "id": "GByujFz6DH3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = linear_model.LogisticRegression(max_iter=2000)\n",
        "logreg.fit(x_train,y_train)\n",
        "Acc_train_max_iter = logreg.score(x_train, y_train)\n",
        "Acc_test_max_iter = logreg.score(x_test, y_test)\n",
        "\n",
        "t = PrettyTable(['Accuracy', 'Logitic Regression (%)', 'Logitic Regression (%) (max_iter)'])\n",
        "t.add_row(['Training', Acc_train*100, Acc_train_max_iter*100])\n",
        "t.add_row(['Testing', Acc_test*100, Acc_test_max_iter*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "T2YFNGeY9LVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A small improvement in model accuracy is achieved with the increase in the max number of iterations. Let us try changing the solver. We will use the 'liblinear' while the default value was 'lbfgs'"
      ],
      "metadata": {
        "id": "KWCD3UiiEwsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = linear_model.LogisticRegression(solver='liblinear')\n",
        "logreg.fit(x_train,y_train)\n",
        "Acc_train_solver = logreg.score(x_train, y_train)\n",
        "Acc_test_solver = logreg.score(x_test, y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logitic Regression (%)', 'Logitic Regression (%) (max_iter)', 'Logitic Regression (%) (solver = liblinear)'])\n",
        "t.add_row(['Training', Acc_train*100, Acc_train_max_iter*100, Acc_train_solver*100])\n",
        "t.add_row(['Testing', Acc_test*100, Acc_test_max_iter*100, Acc_train_solver*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "f8UaqfsW-UU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, some more improvement in performance is achieved."
      ],
      "metadata": {
        "id": "Opkvrx3JF72J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling and/or Normalization"
      ],
      "metadata": {
        "id": "YAuozt7o6bDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try to use feature normalization to improve the performance of the logistic regressor. Here, we will use the MinMaxScaler from sklearn as below"
      ],
      "metadata": {
        "id": "vVQHDaiU6ZR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "\n",
        "scaler.fit(x_train)\n",
        "x_train_normalized = scaler.transform(x_train)\n",
        "x_test_normalized = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "nK3qRhuT6YmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we will fit the logistic model using the scaled features."
      ],
      "metadata": {
        "id": "KQg4t9wvAjQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Acc_train_normalized = logreg.score(x_train_normalized, y_train)\n",
        "Acc_test_normalized = logreg.score(x_test_normalized, y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logitic Regression (%)','Logitic Regression with Normalization(%)'])\n",
        "t.add_row(['Training', Acc_train*100, Acc_train_normalized*100])\n",
        "t.add_row(['Testing', Acc_test*100, Acc_test_normalized*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "im3zy2ax7I-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed, the scaling of features worsen the performance of the model. So we will not scale features."
      ],
      "metadata": {
        "id": "Xf1NDt7RA7A8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oversampling of Features - Class Imbalance "
      ],
      "metadata": {
        "id": "zsAqUJ2b7t5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will try also to oversample the data s that we have a balanced dataset aiming to improve the performance of the logistic regressor. this technique is usually useful if the dataset is not balanced. We will try this technique for illustration although the dataset is already balanced. We will use the SMOTE technique for oversampling."
      ],
      "metadata": {
        "id": "n3fzmk_OA5Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(random_state = 2)\n",
        "x_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())\n",
        "\n",
        "Acc_train_res = logreg.score(x_train_res, y_train_res)\n",
        "Acc_test_res = logreg.score(x_test, y_test)\n",
        "print('The size of the records with cardio = 0 before ovsersampling is {}'.format(sum(y_train==0)))\n",
        "print('The size of the records with cardio = 1 before ovsersampling is {}\\n'.format(sum(y_train==1)))\n",
        "\n",
        "print('The size of the records with cardio = 0 after ovsersampling is {}'.format(sum(y_train_res==0)))\n",
        "print('The size of the records with cardio = 1 after ovsersampling is {}\\n'.format(sum(y_train_res==1)))\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logitic Regression (%)','Logitic Regression with resample(%)'])\n",
        "t.add_row(['Training', Acc_train*100, Acc_train_res*100])\n",
        "t.add_row(['Testing', Acc_test*100, Acc_test_res*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "c1DiuDMY7yWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading Models"
      ],
      "metadata": {
        "id": "_HEZ9o_0YFum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the joblib method from sklearn library (https://scikit-learn.org/stable/modules/model_persistence.html) to save and load the models. To save the model we use the dump method as"
      ],
      "metadata": {
        "id": "bTo0mTb5YHfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib as jb\n",
        "jb.dump(logreg, './Model_logreg.joblib')"
      ],
      "metadata": {
        "id": "xmTG3qJaYQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to load the rained logistic model, we will use the load() method"
      ],
      "metadata": {
        "id": "DhMNaUh0ZRBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_joblib = jb.load('./Model_logreg.joblib')"
      ],
      "metadata": {
        "id": "UXpXcTnWZV88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict New Values Using Models"
      ],
      "metadata": {
        "id": "hR9JhQwVZdud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To predict the target values for new data, we will use the loaded model"
      ],
      "metadata": {
        "id": "3mf1mk6KZhfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.head()"
      ],
      "metadata": {
        "id": "zvnkzBIiZ1R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = logreg_joblib.predict(x_test)\n",
        "dfnew=x_test\n",
        "dfnew['cardio_predict']=y_predict"
      ],
      "metadata": {
        "id": "s9kPkcqbZ9R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the test split, we have the actual value of the 'cardio', so we can add it to the new dataframe for comparison purposes."
      ],
      "metadata": {
        "id": "FYcwiwo6aVy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfnew['cardio_actual']=y_test\n",
        "dfnew.head()"
      ],
      "metadata": {
        "id": "jxyScT03aWXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the measured accuracy above, the cardio_predict and cardio_acutal should match in ~72% (testing accuracy) of the records."
      ],
      "metadata": {
        "id": "alwQnVpUapXb"
      }
    }
  ]
}