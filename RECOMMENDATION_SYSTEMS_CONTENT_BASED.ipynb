{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyPOSVbArZr3A2EE+8MV/iJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/RECOMMENDATION_SYSTEMS_CONTENT_BASED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RECOMMENDATION SYSTEMS - CONTENT-BASED\n"
      ],
      "metadata": {
        "id": "mkRHIvM06yZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate how to build a Healthy Diet Recommender system. We will work on the Healthy Diet datasets from Kaggle (https://www.kaggle.com/code/dhyanidesai/healthy-diet-recommender/data)."
      ],
      "metadata": {
        "id": "1zUsWaQ03Jhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "jKIAXwrfe6wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to import some libraries that will be used during the creation and evaluation of the Decision Tree and Random Forest models."
      ],
      "metadata": {
        "id": "I1fH9Wrse_dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF3_Cpo16WX8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib as jb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "27fY7xYlfKHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the dataset Repository**\n",
        "\n",
        "The dataset can be cloned from the GitHub repository https://github.com/mkjubran/AIData.git as below"
      ],
      "metadata": {
        "id": "Oe_H_szEfL9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./AIData\n",
        "!git clone https://github.com/mkjubran/AIData.git"
      ],
      "metadata": {
        "id": "1aBK80UEfQr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the dataset**\n",
        "\n",
        "The data is stored in the dataset.csv file. Read the input data into a dataframe using the Pandas library (https://pandas.pydata.org/) to read the data."
      ],
      "metadata": {
        "id": "PsR4rC0bfVuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/AIData/HealthyDietRecommender/dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "b4EU2gr-fd4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Data Info**\n",
        "\n",
        "Display some information about the dataset using the info() method"
      ],
      "metadata": {
        "id": "yH3Bs7tegOXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "q4ncJdvtgQi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 512 meal records with 8 features for each record."
      ],
      "metadata": {
        "id": "kMLQzWu9gTPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data"
      ],
      "metadata": {
        "id": "eB7BmZ6NgoCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Missing Values**\n",
        "\n",
        "Check if there are any missing values in the dataset"
      ],
      "metadata": {
        "id": "I6VtkSh0gpgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "VhDBt-Zlh80m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only one meal record has a missing description. We will keep this record so that it will be recommended incase the recommendation is based on the other features."
      ],
      "metadata": {
        "id": "BB_63_j1xsBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection and Encode Features"
      ],
      "metadata": {
        "id": "H_wB8MLGj7Rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this stage we will consider the category, Veg, Nutrient, and Disease features for the recomendation system. \n",
        "\n",
        "We have 78 categories in the category feature, 2 options in the Veg feature, 17 options in the Nutrient feature, 12 diseases in the Disease feature and 16 options in the Diet feature."
      ],
      "metadata": {
        "id": "Q8w24yTwkB_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of categories in the category feature is {}'.format(df['catagory'].unique().size))\n",
        "print('Number of options in the Veg feature is {}'.format(df['Veg_Non'].unique().size))\n",
        "print('Number of options in the Nutrient feature is {}'.format(df['Nutrient'].unique().size))\n",
        "\n",
        "Disease = list(filter(None,list(sorted(set(df['Disease'].sum().replace('[^a-zA-Z ]', '').lower().split(' '))))))\n",
        "print('Number of options in the Disease feature is {}'.format(len(Disease)))\n",
        "\n",
        "Diet = list(filter(None,list(sorted(set(df['Diet'].sum().replace('[^a-zA-Z ]', '').lower().split(' '))))))\n",
        "print('Number of options in the Diet feature is {}'.format(len(Diet)))"
      ],
      "metadata": {
        "id": "jSN-zzGikO8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will encode all of these features using get_dummies() and store them in a separate dataframe"
      ],
      "metadata": {
        "id": "GhZGYDzoliju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catagory_dummies = df.catagory.str.get_dummies()\n",
        "Veg_Non_dummies = df.Veg_Non\t.str.get_dummies()\n",
        "nutrient_dummies = df.Nutrient.str.get_dummies()\n",
        "disease_dummies = df.Disease.str.get_dummies(sep=' ')\n",
        "diet_dummies = df.Diet.str.get_dummies(sep=' ')\n",
        "\n",
        "feature_df = pd.concat([catagory_dummies,Veg_Non_dummies,nutrient_dummies,disease_dummies,diet_dummies],axis=1)\n",
        "feature_df.shape"
      ],
      "metadata": {
        "id": "IsFtZ9jmlR-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of features in the resulting dataframe is 125 features. we will build a recommender system based on these features."
      ],
      "metadata": {
        "id": "tmaFanMQpEK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Unsupervised Nearest Neighbors Model"
      ],
      "metadata": {
        "id": "IH7qAFiRpjvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Unsupervised Nearest Neighbors algorithm from sklearn to "
      ],
      "metadata": {
        "id": "iNhTcATRqWMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "model_NearestNeighbors = NearestNeighbors(n_neighbors=5,algorithm='ball_tree')\n",
        "model_NearestNeighbors.fit(feature_df)"
      ],
      "metadata": {
        "id": "TiVZNWOPqeOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to prepare the format of the input for the recommender system (Input_features). This will be a dictionary that contains the features after get_dummies as keys."
      ],
      "metadata": {
        "id": "l_dHEASiq7pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Input_features = dict()\n",
        "for i in feature_df.columns:\n",
        "    Input_features[i]= 0\n",
        "print(Input_features)"
      ],
      "metadata": {
        "id": "H6KfdX82sCzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading Models"
      ],
      "metadata": {
        "id": "_HEZ9o_0YFum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the joblib method from sklearn library (https://scikit-learn.org/stable/modules/model_persistence.html) to save and load the models. To save the model and the input for the recommender system, we use the dump method as"
      ],
      "metadata": {
        "id": "bTo0mTb5YHfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jb.dump(model_NearestNeighbors, './model_NearestNeighbors.joblib')\n",
        "jb.dump(Input_features, './model_NearestNeighbors_Input_features.joblib')"
      ],
      "metadata": {
        "id": "xmTG3qJaYQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to load the recommender model and the input for the recommender system, we will use the load() method"
      ],
      "metadata": {
        "id": "DhMNaUh0ZRBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_NearestNeighbors_joblib = jb.load('./model_NearestNeighbors.joblib')\n",
        "Input_features_joblib = jb.load('./model_NearestNeighbors_Input_features.joblib')"
      ],
      "metadata": {
        "id": "UXpXcTnWZV88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommend Meals After Loading Models"
      ],
      "metadata": {
        "id": "hR9JhQwVZdud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To recommend a meal after loading the model, we need first to read the dataset."
      ],
      "metadata": {
        "id": "T56YFrM91LRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ALoad = pd.read_csv('/content/AIData/HealthyDietRecommender/dataset.csv')\n",
        "df_ALoad.head()"
      ],
      "metadata": {
        "id": "kxsX0s8Z1UdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the loaded recommender model, we need to get the values of the features for any input. Next, we will assume a sample input, then we will map this input to the existing features in feature_df dataframe, and produce the output vector final_input. The value of every feature in the final_input vector will equal one if the feature is available in the sample input, otherwise, it equals zero."
      ],
      "metadata": {
        "id": "TV3zwKbc1kWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = ['high_protien_diet','gluten_free_diet','diabeties','anemia','calcium','protien']\n",
        "\n",
        "for i in sample_input:\n",
        "    \n",
        "    Input_features_joblib[i] = 1\n",
        "\n",
        "final_input = list(Input_features_joblib.values())\n",
        "print(final_input)"
      ],
      "metadata": {
        "id": "kgAWVcbz1ktG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the most recommended meals, we will apply the final_input vector to the loaded model"
      ],
      "metadata": {
        "id": "A9auBNgt114R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distnaces , indices = model_NearestNeighbors_joblib.kneighbors([final_input])"
      ],
      "metadata": {
        "id": "z4p5L9-q14iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will return the indices of the closest records and the distance between them and the sample input."
      ],
      "metadata": {
        "id": "PJyRQ57q1-Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(distnaces , indices)"
      ],
      "metadata": {
        "id": "yTpK29Sz2AVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will print the list of recommended records from the original dataset (before feature selection and encoding)"
      ],
      "metadata": {
        "id": "DnDqTC2-2DaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(columns=list(df_ALoad.columns))\n",
        "\n",
        "for i in list(indices):\n",
        "    df_results = df_results.append(df_ALoad.loc[i])\n",
        "                \n",
        "df_results = df_results.filter(['Name','Nutrient','Veg_Non','Price','Review','Diet','Disease','description'])\n",
        "df_results = df_results.drop_duplicates(subset=['Name'])\n",
        "df_results = df_results.reset_index(drop=True)\n",
        "df_results"
      ],
      "metadata": {
        "id": "nexRlf5N2GLv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}