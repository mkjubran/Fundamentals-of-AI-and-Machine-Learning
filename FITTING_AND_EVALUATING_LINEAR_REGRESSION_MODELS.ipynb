{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "private_outputs": true,
      "authorship_tag": "ABX9TyPpA6W8f2L8kN2JpmVZ0f9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/FITTING_AND_EVALUATING_LINEAR_REGRESSION_MODELS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FITTING AND EVALUATING LINEAR REGRESSION MODELS\n"
      ],
      "metadata": {
        "id": "mkRHIvM06yZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate how to build and evaluate linear regression models. We will work on part of the modified version of the cardiovascular dataset from Kaggle (https://www.kaggle.com/code/sulianova/eda-cardiovascular-data/data). \n"
      ],
      "metadata": {
        "id": "feNheewKncuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n",
        "\n",
        "First, we need to import some libraries that will be used during the creation and evaluation of linear regression models."
      ],
      "metadata": {
        "id": "a22I7u5jn9cs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF3_Cpo16WX8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "i70MWGnmfiND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the dataset Repository**\n",
        "\n",
        "The modified dataset can be cloned from the GitHub repository https://github.com/mkjubran/AIData.git as below"
      ],
      "metadata": {
        "id": "wmeVq7wzoVpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./AIData\n",
        "!git clone https://github.com/mkjubran/AIData.git"
      ],
      "metadata": {
        "id": "ADXhMdRdolJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the dataset**\n",
        "\n",
        "The data is stored in the MedicalCostPersonalDatasets.csv file. Read the input data into a dataframe using the Pandas library (https://pandas.pydata.org/) to read the data."
      ],
      "metadata": {
        "id": "YfPu_Lw9dhX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/AIData/MedicalCostPersonalDatasets.csv\",sep=\",\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Ul17kybYxun8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Data Info**\n",
        "\n",
        "Display some information about the dataset using the info() method"
      ],
      "metadata": {
        "id": "g-Dl0uSgd3r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "dWEFoS650o5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 1338 records with 6 features for each record. Four features are numeric and the rest are objects (strings)."
      ],
      "metadata": {
        "id": "svFO8hA3eaRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data and Remove Outliers"
      ],
      "metadata": {
        "id": "krq9umG4fqxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Missing Values**\n",
        "\n",
        "Check if there are any missing values in the dataset"
      ],
      "metadata": {
        "id": "uZxpIAF84Waz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "EPCkGtQHeWpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed, no missing data in the dataset."
      ],
      "metadata": {
        "id": "zmwnlkBBey4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Outliers**\n",
        "\n",
        "Let us get the description of the dataset and check if there is anything not normal"
      ],
      "metadata": {
        "id": "xwc5dG0he7Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "YOyyqBSzfwNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The minimum age is 18 years which is the age at which a person can get an insurance plan. According to the records, the maximum age is 64 years. The ideal value of the bmi feature should be between 18.5 and 24.9, so there are records in the dataset for persons with non-ideal bmi values. The number of children is between 0 (no children) and 5. And the charges feature which is the target feature is always positive."
      ],
      "metadata": {
        "id": "TupUl_otgM1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the box plot to check for any outliers in the dataset. As for the 'children' feature, its value is between 0 and 5, and thus no outliers. Let us check for the 'age' and 'bmi' features (independent variables)."
      ],
      "metadata": {
        "id": "ogxY7t3-ioq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df[[\"age\", \"bmi\"]])"
      ],
      "metadata": {
        "id": "ehVoxsnG3qmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no outliers for the 'age' feature and there are few outliers for the 'bmi' feature. The values of these outliers have values close to the third quartile, thus we will not remove them. Let us check the outliers in the 'charges' feature."
      ],
      "metadata": {
        "id": "Ft_bIGZOA04i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df[[\"charges\"]])"
      ],
      "metadata": {
        "id": "QFQ4DDUgCFmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many outliers above the third quartile. Before handling them, let us check the distribution of the 'charges' feature."
      ],
      "metadata": {
        "id": "iuvAnqBUCPqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.distplot(df['charges'], kde = False, color ='blue', bins = 30)"
      ],
      "metadata": {
        "id": "PAvpezgK4wVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the outliers appeared in the boxplot because the 'charges' feature has a skewed distribution which is due to the fact that most of the records are for medication that has low and moderate costs and only few records for high costs. So we should keep these high charges so that the regression model can predict them."
      ],
      "metadata": {
        "id": "kxR5Q_RfCfzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Categorical Data and Check the Significance of Features"
      ],
      "metadata": {
        "id": "JTyT-psEfw1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode Categorical Features**\n",
        "\n",
        "The 'sex', 'smoker', and 'region' are three categorical features that we need to encode. We will encode them using one hot encoding."
      ],
      "metadata": {
        "id": "-GVOjr2WK-hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RWFiYGimLr1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to drop one of the columns that resulted from the hot encoding of each feature. Also, make sure that the original features ('sex', 'smoker', and 'region') are dropped too."
      ],
      "metadata": {
        "id": "IgIS_x2wL8a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['sex_male','region_northeast','smoker_no'],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IgPRICRwMKpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check the significance of features for the regression model**\n",
        "\n",
        "Next ew will use the statistical models to check the significance of every feature for the regression model "
      ],
      "metadata": {
        "id": "rh8NmSGhUX9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop('charges',axis=1)\n",
        "Y=df.charges\n",
        "X = sm.add_constant(X, prepend=True)\n",
        "lm = sm.OLS(endog=Y, exog=X,)\n",
        "lm = lm.fit()\n",
        "print(lm.summary())"
      ],
      "metadata": {
        "id": "ksQLDh9QKuxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieves an R-squared of 0.751, which means that the model manages to explain 75.1% of the variability observed in the charges. The Adj. R-squared is 0.749 which shows the goodness of the regression model (above 0.5 is good). Also, the p-values of all the features except 'sex_female' and 'region_northwest' is significant (lower value means rejecting the Null Hypotheses that the feature does not influence the target feature)."
      ],
      "metadata": {
        "id": "g_TJvaCGUvjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform And Evaluate Linear Regression"
      ],
      "metadata": {
        "id": "_-xit-VMgB9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing Linear Regression**\n",
        "\n",
        "We will start by splitting the dataset into training and testing splits of the dataset, the split ratio is usually 80% training and 20% testing."
      ],
      "metadata": {
        "id": "fuTsxP4vW-Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=200)\n",
        "print('Size of the dataset = {}'.format(len(X)))\n",
        "print('Size of the training dataset = {} ({}%)'.format(len(x_train), 100*len(x_train)/len(X)))\n",
        "print('Size of the testing dataset = {} ({}%)'.format(len(x_test), 100*len(x_test)/len(X)))"
      ],
      "metadata": {
        "id": "FMPttiwlbQJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we used a random_state so that the results are reproducible. You should avoid setting this argument in your production code so that the split is random at every run.\n",
        "\n",
        "Now, we will import the regression model from sklearn and train the model using the training split of the dataset."
      ],
      "metadata": {
        "id": "aiiu37JAcyEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "lm = linear_model.LinearRegression()\n",
        "lm.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "svJnUGfuc-9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Linear Regression**\n",
        "\n",
        "To evaluate the model, we will compute the R2-score using the training and testing splits of the dataset"
      ],
      "metadata": {
        "id": "tjnAhoRWdFMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R2Score_train = lm.score(x_train, y_train)\n",
        "R2Score_test = lm.score(x_test, y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['R2-Score', 'Linear Regression (%)'])\n",
        "t.add_row(['Training', R2Score_train*100])\n",
        "t.add_row(['Testing', R2Score_test*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "DbGkaN1Vd0A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try to perform the linear regression but without the less significant features; 'sex_female' and 'region_northwest'."
      ],
      "metadata": {
        "id": "myU3ZjaUgUWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X2=df.drop(['sex_female', 'region_northwest','charges'], axis=1)\n",
        "Y2=df.charges\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(X2,Y2,test_size=0.2, random_state=200)\n",
        "lm.fit(x2_train,y2_train)\n",
        "R2Score_train = lm.score(x2_train, y2_train)\n",
        "R2Score_test = lm.score(x2_test, y2_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['R2-Score', 'Linear Regression (%)'])\n",
        "t.add_row(['Training', R2Score_train*100])\n",
        "t.add_row(['Testing', R2Score_test*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "v5QCP0PFg0ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So dropping the 'sex_female' and 'region_northwest' did not improve the R2-score.\n",
        "\n",
        "**Polynomial Regression**\n",
        "\n",
        "Let us try polynomial regression to improve the performance of linear regression."
      ],
      "metadata": {
        "id": "x6MtDH-sh7eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_reg  = PolynomialFeatures(degree=2)\n",
        "Xp = poly_reg.fit_transform(X)\n",
        "xp_train, xp_test, yp_train, yp_test = train_test_split(Xp,Y,test_size=0.2, random_state=200)\n",
        "lm.fit(xp_train,yp_train)\n",
        "R2Score_train_poly = lm.score(xp_train, yp_train)\n",
        "R2Score_test_poly = lm.score(xp_test, yp_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['R2-Score', 'Linear Regression (%)', 'Polynomial Regression - 2nd order (%)'])\n",
        "t.add_row(['Training', R2Score_train*100, R2Score_train_poly*100])\n",
        "t.add_row(['Testing', R2Score_test*100, R2Score_test_poly*100])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "V_xcned-iUZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed the polynomial regression provided a better R2-score."
      ],
      "metadata": {
        "id": "rbPdUplTjDW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading Models"
      ],
      "metadata": {
        "id": "HYps7zzLjOMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will learn how to save and load models. We will do that using two methods; Pickle and Joblib.\n",
        "\n",
        "Option #1: we will save the regression model using pickle library (https://docs.python.org/3/library/pickle.html)."
      ],
      "metadata": {
        "id": "n1HfhBimjid9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('./Model.pickle','wb') as f:\n",
        "  pickle.dump(lm,f)\n",
        "\n",
        "with open('./poly_reg.pickle','wb') as f:\n",
        "  pickle.dump(poly_reg,f)"
      ],
      "metadata": {
        "id": "89jl0fj4jyrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The linear model and the transformation are saved in your current directory (.\\content). It doesn't include the dataframes or any other libraries.\n",
        "\n",
        "We will load the models useing the load() method from the pickle library as"
      ],
      "metadata": {
        "id": "Suzs2Yi6kCsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./Model.pickle','rb') as f:\n",
        "  lm_pickle = pickle.load(f)\n",
        "\n",
        "with open('./poly_reg.pickle','rb') as f:\n",
        "  poly_reg_pickle = pickle.load(f)"
      ],
      "metadata": {
        "id": "SfIX6hYBkTZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option#2: Another option is to save the models using joblib from sklearn library (https://scikit-learn.org/stable/modules/model_persistence.html) as"
      ],
      "metadata": {
        "id": "8Rm7aCLpk-cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib as jb\n",
        "jb.dump(lm, './Model.joblib') \n",
        "jb.dump(poly_reg, './poly_reg.joblib') "
      ],
      "metadata": {
        "id": "WEHVxstKlWPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to lead these models, we will use the load() method"
      ],
      "metadata": {
        "id": "rkdeBuYSlk1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_joblib = jb.load('./Model.joblib')\n",
        "poly_reg_joblib = jb.load('./poly_reg.joblib')\n"
      ],
      "metadata": {
        "id": "HkQEcdiZlt13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict New Values Using Models"
      ],
      "metadata": {
        "id": "NdUwUAC-l3bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To predict the target values for new data, we will use the loaded models"
      ],
      "metadata": {
        "id": "WeXrX7JemAPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.head()"
      ],
      "metadata": {
        "id": "PV4aT03um4rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_new=x_test.copy()\n",
        "xp_test = poly_reg_pickle.transform(x_new)\n",
        "y_predict = lm_pickle.predict(xp_test)\n",
        "dfnew=x_new\n",
        "dfnew['charges_predict']=y_predict\n",
        "dfnew.head()"
      ],
      "metadata": {
        "id": "BTERnZkDmLZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}