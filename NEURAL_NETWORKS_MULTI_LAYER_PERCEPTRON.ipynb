{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyMvJTqLFORKj58mTLJ4ITsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/NEURAL_NETWORKS_MULTI_LAYER_PERCEPTRON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting and Evaluating Multi-layer Perceptron\n"
      ],
      "metadata": {
        "id": "mkRHIvM06yZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate how to fit and evaluate a Multi-layer Perceptron (MLP). We will work on a modified version of the cardiovascular dataset from Kaggle (https://www.kaggle.com/code/sulianova/eda-cardiovascular-data/data)."
      ],
      "metadata": {
        "id": "1zUsWaQ03Jhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "jKIAXwrfe6wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to import some libraries that will be used during the creation and evaluation of an MLP model."
      ],
      "metadata": {
        "id": "I1fH9Wrse_dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF3_Cpo16WX8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "27fY7xYlfKHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the dataset Repository**\n",
        "\n",
        "The prepared dataset after cleaning, removing outliers, and feature engineering can be cloned from the GitHub repository https://github.com/mkjubran/AIData.git as below"
      ],
      "metadata": {
        "id": "Oe_H_szEfL9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./AIData\n",
        "!git clone https://github.com/mkjubran/AIData.git"
      ],
      "metadata": {
        "id": "1aBK80UEfQr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the dataset**\n",
        "\n",
        "The data is stored in the cardio_EDA.csv file. Read the input data into a dataframe using the Pandas library (https://pandas.pydata.org/) to read the data."
      ],
      "metadata": {
        "id": "PsR4rC0bfVuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/AIData/cardio_EDA.csv\",sep=\";\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "b4EU2gr-fd4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Data Info**\n",
        "\n",
        "Display some information about the dataset using the info() method"
      ],
      "metadata": {
        "id": "yH3Bs7tegOXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "q4ncJdvtgQi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 53659 records with 15 features for each record. Twelve features are numeric and the rest are objects (strings)."
      ],
      "metadata": {
        "id": "kMLQzWu9gTPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data and Remove Outliers"
      ],
      "metadata": {
        "id": "eB7BmZ6NgoCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data has been processed in previous notebooks\n",
        "- Data Cleaning: https://github.com/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/EXPLORATORY_DATA_ANALYSIS_%E2%80%93_DATA_CLEANING.ipynb\n",
        "- Feature Selection and Feature Engineering: https://github.com/mkjubran/Fundamentals-of-AI-and-Machine-Learning/blob/main/EXPLORATORY_DATA_ANALYSIS_%E2%80%93_FEATURE_SELECTION_AND_FEATURE_ENGINEERING.ipynb\n",
        "\n",
        "As we noticed from the presented sample of the dataset above some features are highly correlated such as the age and the age_year features. So we need to drop one of these features. Besides, we will drop any not needed features such as the 'id' feature."
      ],
      "metadata": {
        "id": "I6VtkSh0gpgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['id','age'],axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "VhDBt-Zlh80m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Categorical Data"
      ],
      "metadata": {
        "id": "xjZQyakaiUEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use hot encoding through the get_dummies() method in pandas to encode the data in the 'gender' and 'smoke' features."
      ],
      "metadata": {
        "id": "WsvvhZVUiVtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1kLKojV1iyhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to drop one of the columns that resulted from the hot encoding of each feature. Also, make sure that the original features ('age' and 'smoke') are dropped too."
      ],
      "metadata": {
        "id": "dAiSWbjYi_73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['gender_female','smoke_No'],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "glXLVzQYjUI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train And Evaluate MLP Classifier"
      ],
      "metadata": {
        "id": "WOdszHgjjcmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train MLP Classifier**\n",
        "\n",
        "We will start by specifying the independent variables and the dependent variable. The independent variables are the features that will be used to predict the target feature (class,label). And the dependent variable is the target feature (class, label)."
      ],
      "metadata": {
        "id": "uAVn-ZTbjgSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# independent variables\n",
        "X=df.drop(['cardio'],axis=1)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "raz1iL76kKAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dependet variable (target feature, class, label)\n",
        "Y=df.cardio\n",
        "Y.head()"
      ],
      "metadata": {
        "id": "eluEJ2uhkihU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will import the MLP classifier model from sklearn and use the Cross-Validation method to evaluate the performance of the model"
      ],
      "metadata": {
        "id": "8F-qHhqtk7J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "model_nn = MLPClassifier()\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv_value = 10\n",
        "\n",
        "Score_nn = cross_validate(model_nn,X,Y,cv = cv_value, return_train_score=True)\n"
      ],
      "metadata": {
        "id": "MXwiJebCe3lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average performance measures of the model are"
      ],
      "metadata": {
        "id": "3bEb-0Jc4VfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ACC_test_nn = np.mean(Score_nn['test_score'])\n",
        "ACC_train_nn = np.mean(Score_nn['train_score'])\n",
        "fit_time_nn = np.mean(Score_nn['fit_time'])\n",
        "score_time_nn = np.mean(Score_nn['score_time'])\n",
        "\n",
        "print('fit_time = {}'.format(fit_time_nn))\n",
        "print('score_time = {}'.format(score_time_nn))\n",
        "print('train_score = {}'.format(ACC_train_nn))\n",
        "print('test_score = {}'.format(ACC_test_nn))"
      ],
      "metadata": {
        "id": "gddFZUUY4V3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will compare NN with the the Random Forest Classifier."
      ],
      "metadata": {
        "id": "b4zZsq2i7jY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Ranom Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Score_rf = cross_validate(RandomForestClassifier(),X,Y,return_train_score=True)\n",
        "ACC_test_rf = np.mean(Score_rf['test_score'])\n",
        "ACC_train_rf = np.mean(Score_rf['train_score'])\n",
        "fit_time_rf = np.mean(Score_rf['fit_time'])\n",
        "score_time_rf = np.mean(Score_rf['score_time'])\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'RF', 'MLP'])\n",
        "t.add_row(['Training (%)', ACC_train_rf*100, ACC_train_nn*100])\n",
        "t.add_row(['Testing (%)', ACC_test_rf*100,  ACC_test_nn*100])\n",
        "t.add_row(['fit_time', fit_time_rf, fit_time_nn])\n",
        "t.add_row(['score_time', score_time_rf, score_time_nn])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "PI5zCqiJ7n5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the K-fold Cross-Validation notebook, we did a grid search to imporove the performance of the RF. We found out that setting the max_features=3, max_samples=2000, and n_estimators=200 improves the performance of RF."
      ],
      "metadata": {
        "id": "sR6DKZPo-ipT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Score_rf = cross_validate(RandomForestClassifier(max_features=3,max_samples=2000,n_estimators=200),X,Y,return_train_score=True)\n",
        "ACC_test_rf_optimized = np.mean(Score_rf['test_score'])\n",
        "ACC_train_rf_optimized = np.mean(Score_rf['train_score'])\n",
        "fit_time_rf_optimized = np.mean(Score_rf['fit_time'])\n",
        "score_time_rf_optimized = np.mean(Score_rf['score_time'])\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'RF', 'RF Optimized','MLP'])\n",
        "t.add_row(['Training (%)', ACC_train_rf*100, ACC_train_rf_optimized*100, ACC_train_nn*100])\n",
        "t.add_row(['Testing (%)', ACC_test_rf*100, ACC_test_rf_optimized*100,  ACC_test_nn*100])\n",
        "t.add_row(['fit_time', fit_time_rf, fit_time_rf_optimized, fit_time_nn])\n",
        "t.add_row(['score_time', score_time_rf, score_time_rf_optimized, score_time_nn])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "Bu4GYZMZ_Gel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To optimize the MLP"
      ],
      "metadata": {
        "id": "am7hhFvHAlDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Score_nn = cross_validate(MLPClassifier(hidden_layer_sizes=(100,)),X,Y,cv = cv_value, return_train_score=True)\n",
        "ACC_test_nn_optimized = np.mean(Score_nn['test_score'])\n",
        "ACC_train_nn_optimized = np.mean(Score_nn['train_score'])\n",
        "fit_time_nn_optimized = np.mean(Score_nn['fit_time'])\n",
        "score_time_nn_optimized = np.mean(Score_nn['score_time'])\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'RF', 'RF Optimized','MLP', 'MLP Optimized'])\n",
        "t.add_row(['Training (%)', ACC_train_rf*100, ACC_train_rf_optimized*100, ACC_train_nn*100, ACC_train_nn_optimized*100])\n",
        "t.add_row(['Testing (%)', ACC_test_rf*100, ACC_test_rf_optimized*100,ACC_test_nn*100,ACC_test_nn_optimized*100])\n",
        "t.add_row(['fit_time', fit_time_rf, fit_time_rf_optimized, fit_time_nn,fit_time_nn_optimized])\n",
        "t.add_row(['score_time', score_time_rf, score_time_rf_optimized, score_time_nn,score_time_nn_optimized])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "-If2YAhsA1qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will fit an MLP model using all the data we have"
      ],
      "metadata": {
        "id": "4at1zLbcCBHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "model_nn = MLPClassifier(hidden_layer_sizes=(100,))\n",
        "model_nn.fit(X,Y)"
      ],
      "metadata": {
        "id": "f0iBrs3oCGJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading Models"
      ],
      "metadata": {
        "id": "_HEZ9o_0YFum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the joblib method from sklearn library (https://scikit-learn.org/stable/modules/model_persistence.html) to save and load the models. To save the model we use the dump method as"
      ],
      "metadata": {
        "id": "bTo0mTb5YHfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib as jb\n",
        "jb.dump(model_nn, './Model_nn.joblib')"
      ],
      "metadata": {
        "id": "xmTG3qJaYQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to load the trained random forest model, we will use the load() method"
      ],
      "metadata": {
        "id": "DhMNaUh0ZRBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn_joblib = jb.load('./Model_nn.joblib')"
      ],
      "metadata": {
        "id": "UXpXcTnWZV88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict New Values Using Models"
      ],
      "metadata": {
        "id": "hR9JhQwVZdud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To predict the target values for new data, we will use the loaded model and any data"
      ],
      "metadata": {
        "id": "3mf1mk6KZhfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = X.head(20)\n",
        "y_test = Y.head(20)"
      ],
      "metadata": {
        "id": "zvnkzBIiZ1R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model_nn_joblib.predict(x_test)\n",
        "dfnew=x_test.copy()\n",
        "dfnew['cardio_predict']=y_predict"
      ],
      "metadata": {
        "id": "s9kPkcqbZ9R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the test split, we have the actual value of the 'cardio', so we can add it to the new dataframe for comparison purposes."
      ],
      "metadata": {
        "id": "FYcwiwo6aVy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfnew['cardio_actual']=y_test\n",
        "dfnew.head()"
      ],
      "metadata": {
        "id": "jxyScT03aWXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the measured accuracy above, the cardio_predict and cardio_acutal should match in ~70% (testing accuracy) of the records."
      ],
      "metadata": {
        "id": "alwQnVpUapXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfnew[dfnew['cardio_predict'] != dfnew['cardio_actual']]"
      ],
      "metadata": {
        "id": "wRDqOh4BnOQK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}